{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiw5thAImeFb3vEBCzXynr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tranvietphi20104051/baitapAI/blob/main/phanmain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Jzy072YaTFA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "from modules.text_recognition.vietocr.tool.predictor import Predictor\n",
        "from modules.text_recognition.vietocr.tool.config import Cfg\n",
        "from modules.detect_word import OCR\n",
        "from modules.crop_image import CropImg\n",
        "\n",
        "\n",
        "def vietnamese_ocr():\n",
        "    config = Cfg.load_config_from_name('vgg_transformer')\n",
        "    config['weights'] = './models/transformerocr.pth'\n",
        "    config['cnn']['pretrained'] = False\n",
        "    config['device'] = 'cpu'\n",
        "    config['predictor']['beamsearch'] = False\n",
        "    detector = Predictor(config)\n",
        "    return detector\n",
        "\n",
        "\n",
        "def id_card_ocr(path, run=False):\n",
        "    if run:\n",
        "        IMG_SIZE = 640\n",
        "        model_crop = torch.hub.load('ultralytics/yolov5', 'custom', path='models/yolov5_l6_cccd.pt')\n",
        "        detect_model = torch.hub.load('ultralytics/yolov5', 'custom', path='models/information_yolov5l.pt')\n",
        "        nlp_model = vietnamese_ocr()\n",
        "        img = cv2.imread(path)\n",
        "        crop = model_crop(img, IMG_SIZE)\n",
        "\n",
        "        for i in range(len(crop.xyxy)):\n",
        "            for i in range(len(crop.xyxy)):\n",
        "                image_crop = CropImg(crop.xyxy[i], crop.pandas().xyxy[i], img)\n",
        "                detect_id_card = detect_model(image_crop, IMG_SIZE)\n",
        "                print(detect_id_card)\n",
        "                for j in range(len(detect_id_card.xyxy)):\n",
        "                    dictionary = OCR(detect_id_card.xyxy[j], detect_id_card.pandas().xyxy[j], image_crop, nlp_model)\n",
        "                    return dictionary\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    id_card_ocr(run=False)\n"
      ]
    }
  ]
}